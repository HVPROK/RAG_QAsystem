# ğŸ§  Retrieval-Augmented Generation (RAG) Q&A System

This project implements a **Retrieval-Augmented Generation (RAG)** system using **Streamlit** for the user interface and the **Gemini API** as the Large Language Model (LLM).  
It is designed to answer user queries based on a fixed knowledge base, providing **accurate responses** with an associated **confidence score**.

---

## ğŸš€ Features

- **Interactive Streamlit Interface** for real-time Q&A.  
- **RAG Pipeline** that retrieves context before generating an answer.  
- **Embeddings with `all-MiniLM-L6-v2`** for semantic search.  
- **FAISS Vector Store** for efficient similarity-based document retrieval.  
- **Confidence Scoring System** to indicate response reliability.

---

## âš™ï¸ Setup Instructions

1. Install Dependencies
pip install -r requirements.txt
2. Run the Streamlit App
bash
Copy code
streamlit run rag_app.py

---

## ğŸ§© Design Overview
The RAG system follows a modular architecture with clear separation between document retrieval and answer generation.

ğŸ”¹ Embedding Model
Uses all-MiniLM-L6-v2 to convert documents and queries into vector embeddings.

ğŸ”¹ Vector Store
Employs FAISS (Facebook AI Similarity Search) for fast and scalable cosine similarity-based search.

ğŸ”¹ LLM Integration
The Gemini API is used for generating final answers after retrieving the most relevant context.

---

## ğŸ“Š Confidence Score Calculation

The confidence score represents how relevant the retrieved context is to the user query.

Confidence=MeanÂ ofÂ Top-kÂ CosineÂ SimilarityÂ Scores

This score provides a transparent measure of how much the model â€œtrustsâ€ its retrieved data.

---

## ğŸ”® Future Improvements
If given additional time, the system can be enhanced for production readiness and scalability with the following improvements:

ğŸ§µ 1. Asynchronous Ingestion & Queuing
Implement a background ingestion system for large documents.

Allow users to upload PDFs without blocking the main thread.

ğŸ—ƒï¸ 2. Message Queue Integration
Use Redis or RabbitMQ to manage ingestion and retrieval requests.

Prevent long-running processes from blocking the application.

Support multiple concurrent users smoothly.

âš™ï¸ 3. Enhanced Architecture
Introduce an asynchronous pipeline for vectorization and retrieval.

Enable scalable deployment through containerization or microservices.

Vector Store	FAISS
Backend	Python
Task Queue (Future)	Redis / RabbitMQ

---

## ğŸ§  Architecture Diagram
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        User Query          â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚     Streamlit UI     â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Embedding Model (MiniLM-L6)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                             â”‚
                â–¼                             â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Knowledge Base   â”‚  ----->  â”‚  FAISS Vector Store  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   Top-k Relevant Chunks   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   Gemini LLM (Answer)    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  Final Response  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                     
---

## ğŸ§‘â€ğŸ’» Author

**Harikrishnan V**  
AI Engineer | Machine Learning & RAG Systems Developer  

ğŸ”— [LinkedIn](https://www.linkedin.com/in/harivansu)  
ğŸ’» [GitHub](https://github.com/yourusername)

